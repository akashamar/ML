layers:

- Input layers: the number of input layer will be equal to the features available in dataset
- Hidden layer
- output layer

Hidden layer:

- Each neuron has weight and a value which will be from 0 to 1
- Weight of the neuron: w = (a1*w1)+(a2*w2)+(a3*w3)+.....+(an*wn) + b(bias)
- Calculating the weight-age sum of next layer: a23 = activation_function((a1*w1)+(a2*w2)+(a3*w3)+.....+(an*wn) + b(bias))

Functions used:

- Sigmoid (slow learner)
- ReLU (fast learner)

One hot encoding:
* converting the number to array with zero and 1 in the place of the actual number as index

For loss function
* For discrete y_train use parse_categorical_entropy
* For one hot encoding or categorical y_train use categorical_entropy

For binary output:
activation function: sigmoid
loss function: binary_crossentropy
